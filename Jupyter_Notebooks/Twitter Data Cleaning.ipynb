{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Import Libraries</a></span></li></ul></li><li><span><a href=\"#Import-Data\" data-toc-modified-id=\"Import-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Import Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-searched-tweets\" data-toc-modified-id=\"Load-searched-tweets-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Load searched tweets</a></span></li><li><span><a href=\"#Load-tweet-deets\" data-toc-modified-id=\"Load-tweet-deets-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Load tweet deets</a></span></li><li><span><a href=\"#Load-users\" data-toc-modified-id=\"Load-users-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Load users</a></span></li></ul></li><li><span><a href=\"#Convert-Tweets-To-DataFrames\" data-toc-modified-id=\"Convert-Tweets-To-DataFrames-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Convert Tweets To DataFrames</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tweets-JSONs-To-DataFrames\" data-toc-modified-id=\"Tweets-JSONs-To-DataFrames-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Tweets JSONs To DataFrames</a></span></li><li><span><a href=\"#Deets-JSONs-To-DataFrames\" data-toc-modified-id=\"Deets-JSONs-To-DataFrames-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Deets JSONs To DataFrames</a></span></li><li><span><a href=\"#Users-JSONs-To-DataFrames\" data-toc-modified-id=\"Users-JSONs-To-DataFrames-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Users JSONs To DataFrames</a></span></li></ul></li><li><span><a href=\"#Merge-DataFrames-Into-One\" data-toc-modified-id=\"Merge-DataFrames-Into-One-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Merge DataFrames Into One</a></span><ul class=\"toc-item\"><li><span><a href=\"#Convert-ID-Strings-To-Integers\" data-toc-modified-id=\"Convert-ID-Strings-To-Integers-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Convert ID Strings To Integers</a></span></li><li><span><a href=\"#Merge-&quot;Tweets&quot;-DataFrames-With-&quot;Deets&quot;-DataFrames\" data-toc-modified-id=\"Merge-&quot;Tweets&quot;-DataFrames-With-&quot;Deets&quot;-DataFrames-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Merge \"Tweets\" DataFrames With \"Deets\" DataFrames</a></span></li><li><span><a href=\"#Merge-&quot;Tweets-+-Deets&quot;-DataFrames-With-&quot;Users&quot;-DataFrames\" data-toc-modified-id=\"Merge-&quot;Tweets-+-Deets&quot;-DataFrames-With-&quot;Users&quot;-DataFrames-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Merge \"Tweets + Deets\" DataFrames With \"Users\" DataFrames</a></span></li><li><span><a href=\"#Concat-All-&quot;Merged&quot;-DataFrames-Together-Into-One-Big-DataFrame\" data-toc-modified-id=\"Concat-All-&quot;Merged&quot;-DataFrames-Together-Into-One-Big-DataFrame-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Concat All \"Merged\" DataFrames Together Into One Big DataFrame</a></span></li></ul></li><li><span><a href=\"#Export-Raw-DataFrame\" data-toc-modified-id=\"Export-Raw-DataFrame-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Export Raw DataFrame</a></span></li><li><span><a href=\"#Column-Cleaning\" data-toc-modified-id=\"Column-Cleaning-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Column Cleaning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Feature Engineering</a></span></li><li><span><a href=\"#Drop-columns\" data-toc-modified-id=\"Drop-columns-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Drop columns</a></span></li><li><span><a href=\"#Convert-Column-Data-Types\" data-toc-modified-id=\"Convert-Column-Data-Types-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Convert Column Data Types</a></span></li></ul></li><li><span><a href=\"#Filter-DataFrame-Rows-By-&quot;Startup&quot;-Criteria\" data-toc-modified-id=\"Filter-DataFrame-Rows-By-&quot;Startup&quot;-Criteria-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Filter DataFrame Rows By \"Startup\" Criteria</a></span></li><li><span><a href=\"#Imputing-Values-As-Necessary\" data-toc-modified-id=\"Imputing-Values-As-Necessary-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Imputing Values As Necessary</a></span><ul class=\"toc-item\"><li><span><a href=\"#Figure-out-where-NaN-values-are-in-our-data\" data-toc-modified-id=\"Figure-out-where-NaN-values-are-in-our-data-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Figure out where NaN values are in our data</a></span></li><li><span><a href=\"#Drop-rows-where-there-are-NaN-values-in-our-data\" data-toc-modified-id=\"Drop-rows-where-there-are-NaN-values-in-our-data-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Drop rows where there are NaN values in our data</a></span></li></ul></li><li><span><a href=\"#Export-Final-DataFrame\" data-toc-modified-id=\"Export-Final-DataFrame-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Export Final DataFrame</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary python packages and functions\n",
    "from Py_Files.imports import *\n",
    "from Py_Files.max_range import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load searched tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/investing.json') as a:\n",
    "    tweets_investing = json.load(a)\n",
    "with open('../Data/mobile_payment.json') as b:\n",
    "    tweets_mobile_payment = json.load(b)\n",
    "with open('../Data/mobile_wallet.json') as c:\n",
    "    tweets_mobile_wallet = json.load(c)\n",
    "with open('../Data/mobile_banking.json') as d:\n",
    "    tweets_mobile_banking = json.load(d)\n",
    "with open('../Data/trading.json') as e:\n",
    "    tweets_trading = json.load(e)\n",
    "with open('../Data/fintech.json') as f:\n",
    "    tweets_fintech = json.load(f)\n",
    "with open('../Data/financial.json') as g:\n",
    "    tweets_financial = json.load(g)\n",
    "with open('../Data/money_management.json') as h:\n",
    "    tweets_money_management = json.load(h)\n",
    "with open('../Data/stocks.json') as i:\n",
    "    tweets_stocks = json.load(i)\n",
    "with open('../Data/transaction.json') as j:\n",
    "    tweets_transaction = json.load(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tweet deets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/deets_investing.json') as aa:\n",
    "    deets_investing = json.load(aa)\n",
    "with open('../Data/deets_mobile_payment.json') as bb:\n",
    "    deets_mobile_payment = json.load(bb)\n",
    "with open('../Data/deets_mobile_wallet.json') as cc:\n",
    "    deets_mobile_wallet = json.load(cc)\n",
    "with open('../Data/deets_mobile_banking.json') as dd:\n",
    "    deets_mobile_banking = json.load(dd)\n",
    "with open('../Data/deets_trading.json') as ee:\n",
    "    deets_trading = json.load(ee)\n",
    "with open('../Data/deets_fintech.json') as ff:\n",
    "    deets_fintech = json.load(ff)\n",
    "with open('../Data/deets_financial.json') as gg:\n",
    "    deets_financial = json.load(gg)\n",
    "with open('../Data/deets_money_management.json') as hh:\n",
    "    deets_money_management = json.load(hh)\n",
    "with open('../Data/deets_stocks.json') as ii:\n",
    "    deets_stocks = json.load(ii)\n",
    "with open('../Data/deets_transaction.json') as jj:\n",
    "    deets_transaction = json.load(jj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/user_investing.json') as aaa:\n",
    "    users_investing = json.load(aaa)\n",
    "with open('../Data/user_mobile_payment.json') as bbb:\n",
    "    users_mobile_payment = json.load(bbb)\n",
    "with open('../Data/user_mobile_wallet.json') as ccc:\n",
    "    users_mobile_wallet = json.load(ccc)\n",
    "with open('../Data/user_mobile_banking.json') as ddd:\n",
    "    users_mobile_banking = json.load(ddd)\n",
    "with open('../Data/user_trading.json') as eee:\n",
    "    users_trading = json.load(eee)\n",
    "with open('../Data/user_fintech.json') as fff:\n",
    "    users_fintech = json.load(fff)\n",
    "with open('../Data/user_financial.json') as ggg:\n",
    "    users_financial = json.load(ggg)\n",
    "with open('../Data/user_money_management.json') as hhh:\n",
    "    users_money_management = json.load(hhh)\n",
    "with open('../Data/user_stocks.json') as iii:\n",
    "    users_stocks = json.load(iii)\n",
    "with open('../Data/user_transaction.json') as jjj:\n",
    "    users_transaction = json.load(jjj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Tweets To DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets JSONs To DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_column_1(data_source_json, json_key, df_name, df_column_name):\n",
    "    new_list = []\n",
    "    for x in range(len(data_source_json)):\n",
    "        for y in range(len(data_source_json[x]['statuses'])):\n",
    "            new_list.append(data_source_json[x]['statuses'][y][json_key])\n",
    "    df_name[df_column_name] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_column_2(data_source_json, json_key_1, json_key_2, df_name, df_column_name):\n",
    "    new_list = []\n",
    "    for x in range(len(data_source_json)):\n",
    "        for y in range(len(data_source_json[x]['statuses'])):\n",
    "            new_list.append(data_source_json[x]['statuses'][y][json_key_1][json_key_2])\n",
    "    df_name[df_column_name] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_column_3(data_source_json, json_key_1, json_key_2, json_key_3, df_name, df_column_name):\n",
    "    new_list = []\n",
    "    for x in range(len(data_source_json)):\n",
    "        for y in range(len(data_source_json[x]['statuses'])):\n",
    "            new_list.append(data_source_json[x]['statuses'][y][json_key_1][json_key_2][0][json_key_3])\n",
    "    df_name[df_column_name] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_column_4(data_source_json, json_key_1, json_key_2, json_key_3, json_key_4, df_name, df_column_name):\n",
    "    new_list = []\n",
    "    for x in range(len(data_source_json)):\n",
    "        for y in range(len(data_source_json[x]['statuses'])):\n",
    "            new_list.append(data_source_json[x]['statuses'][y][json_key_1][json_key_2][0][json_key_3][json_key_4])\n",
    "    df_name[df_column_name] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframes(df_name, data_source_json):\n",
    "    \n",
    "    #use first function for first-order JSON keys (make_df_column_1)\n",
    "    make_df_column_1(data_source_json, 'created_at', df_name, 'tweets_created_at')\n",
    "    make_df_column_1(data_source_json, 'id', df_name, 'tweets_id')\n",
    "    make_df_column_1(data_source_json, 'source', df_name, 'tweets_source')\n",
    "    make_df_column_1(data_source_json, 'in_reply_to_status_id', df_name, 'tweets_in_reply_to_status_id')\n",
    "    make_df_column_1(data_source_json, 'in_reply_to_user_id', df_name, 'tweets_in_reply_to_user_id')\n",
    "    make_df_column_1(data_source_json, 'in_reply_to_screen_name', df_name, 'tweets_in_reply_to_screen_name')\n",
    "    make_df_column_1(data_source_json, 'coordinates', df_name, 'tweets_coordinates')\n",
    "    make_df_column_1(data_source_json, 'geo', df_name, 'tweets_geo')\n",
    "    make_df_column_1(data_source_json, 'place', df_name, 'tweets_place')\n",
    "    make_df_column_1(data_source_json, 'contributors', df_name, 'tweets_contributors')\n",
    "    make_df_column_1(data_source_json, 'is_quote_status', df_name, 'tweets_is_quote_status')\n",
    "    make_df_column_1(data_source_json, 'favorited', df_name, 'tweets_favorited')\n",
    "    make_df_column_1(data_source_json, 'favorite_count', df_name, 'tweets_favorite_count')\n",
    "    make_df_column_1(data_source_json, 'retweeted', df_name, 'tweets_retweeted')\n",
    "    make_df_column_1(data_source_json, 'retweet_count', df_name, 'tweets_retweet_count')\n",
    "\n",
    "    #use second function for second-order JSON keys (make_df_column_2)\n",
    "    make_df_column_2(data_source_json, 'user', 'id', df_name, 'tweets_user_id')\n",
    "    make_df_column_2(data_source_json, 'user', 'name', df_name, 'tweets_user_name')\n",
    "    make_df_column_2(data_source_json, 'user', 'screen_name', df_name, 'tweet_user_screen_name')\n",
    "    make_df_column_2(data_source_json, 'user', 'location', df_name, 'tweets_user_location')\n",
    "    make_df_column_2(data_source_json, 'user', 'description', df_name, 'tweets_user_description')\n",
    "    make_df_column_2(data_source_json, 'user', 'friends_count', df_name, 'tweets_user_friends_count')\n",
    "    make_df_column_2(data_source_json, 'user', 'followers_count', df_name, 'tweets_user_followers_count')\n",
    "    make_df_column_2(data_source_json, 'user', 'favourites_count', df_name, 'tweets_user_favourites_count')\n",
    "    make_df_column_2(data_source_json, 'user', 'geo_enabled', df_name, 'tweets_user_geo_enabled')\n",
    "    make_df_column_2(data_source_json, 'user', 'verified', df_name, 'tweets_user_verified')\n",
    "    make_df_column_2(data_source_json, 'user', 'statuses_count', df_name, 'tweets_user_statuses_count')\n",
    "    make_df_column_2(data_source_json, 'user', 'profile_background_color', df_name, 'tweets_user_profile_background_color')\n",
    "    make_df_column_2(data_source_json, 'user', 'profile_text_color', df_name, 'tweets_user_profile_text_color')\n",
    "    make_df_column_2(data_source_json, 'user', 'profile_use_background_image', df_name, 'tweets_user_profile_use_background_image')\n",
    "    make_df_column_2(data_source_json, 'user', 'has_extended_profile', df_name, 'tweets_user_has_extended_profile')\n",
    "    make_df_column_2(data_source_json, 'user', 'default_profile', df_name, 'tweets_user_default_profile_image')\n",
    "    make_df_column_2(data_source_json, 'user', 'following', df_name, 'tweets_user_following')\n",
    "    make_df_column_2(data_source_json, 'user', 'follow_request_sent', df_name, 'tweets_user_follow_request_sent')\n",
    "    make_df_column_2(data_source_json, 'user', 'notifications', df_name, 'tweets_user_notifications')\n",
    "\n",
    "    make_df_column_2(data_source_json, 'entities', 'symbols', df_name, 'tweets_entities_symbols')\n",
    "    make_df_column_2(data_source_json, 'entities', 'user_mentions', df_name, 'tweets_entities_user_mentions')\n",
    "    make_df_column_2(data_source_json, 'entities', 'urls', df_name, 'tweets_entities_urls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_investing_df = pd.DataFrame()\n",
    "tweets_mobile_payment_df = pd.DataFrame()\n",
    "tweets_mobile_wallet_df = pd.DataFrame()\n",
    "tweets_mobile_banking_df = pd.DataFrame()\n",
    "tweets_trading_df = pd.DataFrame()\n",
    "tweets_fintech_df = pd.DataFrame()\n",
    "tweets_financial_df = pd.DataFrame()\n",
    "tweets_money_management_df = pd.DataFrame()\n",
    "tweets_stocks_df = pd.DataFrame()\n",
    "tweets_transaction_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dataframes(tweets_investing_df, tweets_investing)\n",
    "make_dataframes(tweets_mobile_payment_df, tweets_mobile_payment)\n",
    "make_dataframes(tweets_mobile_wallet_df, tweets_mobile_wallet)\n",
    "make_dataframes(tweets_mobile_banking_df, tweets_mobile_banking)\n",
    "make_dataframes(tweets_trading_df, tweets_trading)\n",
    "make_dataframes(tweets_fintech_df, tweets_fintech)\n",
    "make_dataframes(tweets_financial_df, tweets_financial)\n",
    "make_dataframes(tweets_money_management_df, tweets_money_management)\n",
    "make_dataframes(tweets_stocks_df, tweets_stocks)\n",
    "make_dataframes(tweets_transaction_df, tweets_transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_created_at</th>\n",
       "      <th>tweets_id</th>\n",
       "      <th>tweets_source</th>\n",
       "      <th>tweets_in_reply_to_status_id</th>\n",
       "      <th>tweets_in_reply_to_user_id</th>\n",
       "      <th>tweets_in_reply_to_screen_name</th>\n",
       "      <th>tweets_coordinates</th>\n",
       "      <th>tweets_geo</th>\n",
       "      <th>tweets_place</th>\n",
       "      <th>tweets_contributors</th>\n",
       "      <th>tweets_is_quote_status</th>\n",
       "      <th>tweets_favorited</th>\n",
       "      <th>tweets_favorite_count</th>\n",
       "      <th>tweets_retweeted</th>\n",
       "      <th>tweets_retweet_count</th>\n",
       "      <th>tweets_user_id</th>\n",
       "      <th>tweets_user_name</th>\n",
       "      <th>tweet_user_screen_name</th>\n",
       "      <th>tweets_user_location</th>\n",
       "      <th>tweets_user_description</th>\n",
       "      <th>tweets_user_friends_count</th>\n",
       "      <th>tweets_user_followers_count</th>\n",
       "      <th>tweets_user_favourites_count</th>\n",
       "      <th>tweets_user_geo_enabled</th>\n",
       "      <th>tweets_user_verified</th>\n",
       "      <th>tweets_user_statuses_count</th>\n",
       "      <th>tweets_user_profile_background_color</th>\n",
       "      <th>tweets_user_profile_text_color</th>\n",
       "      <th>tweets_user_profile_use_background_image</th>\n",
       "      <th>tweets_user_has_extended_profile</th>\n",
       "      <th>tweets_user_default_profile_image</th>\n",
       "      <th>tweets_user_following</th>\n",
       "      <th>tweets_user_follow_request_sent</th>\n",
       "      <th>tweets_user_notifications</th>\n",
       "      <th>tweets_entities_symbols</th>\n",
       "      <th>tweets_entities_user_mentions</th>\n",
       "      <th>tweets_entities_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Fri Jan 31 21:03:41 +0000 2020</td>\n",
       "      <td>1223351165523578885</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>12761</td>\n",
       "      <td>False</td>\n",
       "      <td>3014</td>\n",
       "      <td>284278132</td>\n",
       "      <td>Morgan Housel</td>\n",
       "      <td>morganhousel</td>\n",
       "      <td></td>\n",
       "      <td>@collabfund</td>\n",
       "      <td>487</td>\n",
       "      <td>129374</td>\n",
       "      <td>54543</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>14545</td>\n",
       "      <td>131516</td>\n",
       "      <td>333333</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweets_created_at            tweets_id                                      tweets_source  tweets_in_reply_to_status_id  tweets_in_reply_to_user_id tweets_in_reply_to_screen_name tweets_coordinates tweets_geo tweets_place tweets_contributors  tweets_is_quote_status  tweets_favorited  tweets_favorite_count  tweets_retweeted  tweets_retweet_count  tweets_user_id tweets_user_name tweet_user_screen_name tweets_user_location tweets_user_description  tweets_user_friends_count  tweets_user_followers_count  tweets_user_favourites_count  tweets_user_geo_enabled  tweets_user_verified  tweets_user_statuses_count tweets_user_profile_background_color tweets_user_profile_text_color  tweets_user_profile_use_background_image  tweets_user_has_extended_profile  tweets_user_default_profile_image tweets_user_following tweets_user_follow_request_sent tweets_user_notifications tweets_entities_symbols tweets_entities_user_mentions tweets_entities_urls\n",
       "0  Fri Jan 31 21:03:41 +0000 2020  1223351165523578885  <a href=\"http://twitter.com/download/iphone\" r...                           NaN                         NaN                           None               None       None         None                None                   False             False                  12761             False                  3014       284278132    Morgan Housel           morganhousel                                  @collabfund                        487                       129374                         54543                    False                  True                       14545                               131516                         333333                                      True                              True                              False                  None                            None                      None                      []                            []                   []"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test a dataframe to make sure it worked:\n",
    "tweets_investing_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deets JSONs To DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_column_1_deets(data_source_json, json_key, df_name, df_column_name):\n",
    "    new_list = []\n",
    "    for x in range(len(data_source_json)):\n",
    "        for y in range(len(data_source_json[x]['data'])):\n",
    "            new_list.append(data_source_json[x]['data'][y][json_key])\n",
    "    df_name[df_column_name] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_column_2_deets(data_source_json, json_key_1, json_key_2, df_name, df_column_name):\n",
    "    new_list = []\n",
    "    for x in range(len(data_source_json)):\n",
    "        for y in range(len(data_source_json[x]['data'])):\n",
    "            new_list.append(data_source_json[x]['data'][y][json_key_1][json_key_2])\n",
    "    df_name[df_column_name] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframes_deets(df_name, data_source_json):\n",
    "    \n",
    "    #use first function for first-order JSON keys (make_df_column_1)\n",
    "    make_df_column_1_deets(data_source_json, 'author_id', df_name, 'deets_author_id')\n",
    "    make_df_column_1_deets(data_source_json, 'created_at', df_name, 'deets_created_at')\n",
    "    make_df_column_1_deets(data_source_json, 'id', df_name, 'deets_tweet_id')\n",
    "    make_df_column_1_deets(data_source_json, 'lang', df_name, 'deets_lang')\n",
    "    make_df_column_1_deets(data_source_json, 'possibly_sensitive', df_name, 'deets_possibly_sensitive')\n",
    "    make_df_column_1_deets(data_source_json, 'source', df_name, 'deets_source')\n",
    "    make_df_column_1_deets(data_source_json, 'text', df_name, 'deets_text')\n",
    "\n",
    "    #use second function for second-order JSON keys (make_df_column_2)\n",
    "    make_df_column_2_deets(data_source_json, 'stats', 'reply_count', df_name, 'deets_reply_count')\n",
    "    make_df_column_2_deets(data_source_json, 'stats', 'like_count', df_name, 'deets_like_count')\n",
    "    make_df_column_2_deets(data_source_json, 'stats', 'quote_count', df_name, 'deets_quote_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "deets_investing_df = pd.DataFrame()\n",
    "deets_mobile_payment_df = pd.DataFrame()\n",
    "deets_mobile_wallet_df = pd.DataFrame()\n",
    "deets_mobile_banking_df = pd.DataFrame()\n",
    "deets_trading_df = pd.DataFrame()\n",
    "deets_fintech_df = pd.DataFrame()\n",
    "deets_financial_df = pd.DataFrame()\n",
    "deets_money_management_df = pd.DataFrame()\n",
    "deets_stocks_df = pd.DataFrame()\n",
    "deets_transaction_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dataframes_deets(deets_investing_df, deets_investing)\n",
    "make_dataframes_deets(deets_mobile_payment_df, deets_mobile_payment)\n",
    "make_dataframes_deets(deets_mobile_wallet_df, deets_mobile_wallet)\n",
    "make_dataframes_deets(deets_mobile_banking_df, deets_mobile_banking)\n",
    "make_dataframes_deets(deets_trading_df, deets_trading)\n",
    "make_dataframes_deets(deets_fintech_df, deets_fintech)\n",
    "make_dataframes_deets(deets_financial_df, deets_financial)\n",
    "make_dataframes_deets(deets_money_management_df, deets_money_management)\n",
    "make_dataframes_deets(deets_stocks_df, deets_stocks)\n",
    "make_dataframes_deets(deets_transaction_df, deets_transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deets_author_id</th>\n",
       "      <th>deets_created_at</th>\n",
       "      <th>deets_tweet_id</th>\n",
       "      <th>deets_lang</th>\n",
       "      <th>deets_possibly_sensitive</th>\n",
       "      <th>deets_source</th>\n",
       "      <th>deets_text</th>\n",
       "      <th>deets_reply_count</th>\n",
       "      <th>deets_like_count</th>\n",
       "      <th>deets_quote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>284278132</td>\n",
       "      <td>2020-01-31T21:03:41.000Z</td>\n",
       "      <td>1223351165523578885</td>\n",
       "      <td>en</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Investing.  https://t.co/qQQtVyOLid</td>\n",
       "      <td>195</td>\n",
       "      <td>14083</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  deets_author_id          deets_created_at       deets_tweet_id deets_lang  deets_possibly_sensitive                                       deets_source                           deets_text  deets_reply_count  deets_like_count  deets_quote_count\n",
       "0       284278132  2020-01-31T21:03:41.000Z  1223351165523578885         en                     False  <a href=\"http://twitter.com/download/iphone\" r...  Investing.  https://t.co/qQQtVyOLid                195             14083                444"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deets_investing_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users JSONs To DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_column_1_users(data_source_json, json_key, df_name, df_column_name):\n",
    "    new_list = []\n",
    "    for x in range(len(data_source_json)):\n",
    "        for y in range(len(data_source_json[x]['data'])):\n",
    "            new_list.append(data_source_json[x]['data'][y][json_key])\n",
    "    df_name[df_column_name] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_column_2_users(data_source_json, json_key_1, json_key_2, df_name, df_column_name):\n",
    "    new_list = []\n",
    "    for x in range(len(data_source_json)):\n",
    "        for y in range(len(data_source_json[x]['data'])):\n",
    "            new_list.append(data_source_json[x]['data'][y][json_key_1][json_key_2])\n",
    "    df_name[df_column_name] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df_column_4_users(data_source_json, json_key_1, json_key_2, json_key_3, json_key_4, df_name, df_column_name):\n",
    "    new_list = []\n",
    "    for x in range(len(data_source_json)):\n",
    "        for y in range(len(data_source_json[x]['data'])):\n",
    "            try:\n",
    "                new_list.append(data_source_json[x]['data'][y][json_key_1][json_key_2][json_key_3][0][json_key_4])\n",
    "            except: new_list.append('')\n",
    "            continue\n",
    "    df_name[df_column_name] = new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframes_users(df_name, data_source_json):\n",
    "    \n",
    "    #use first function for first-order JSON keys (make_df_column_1)\n",
    "    make_df_column_1_users(data_source_json, 'id', df_name, 'users_id')\n",
    "    make_df_column_1_users(data_source_json, 'created_at', df_name, 'users_created_at')\n",
    "    make_df_column_1_users(data_source_json, 'description', df_name, 'users_description')\n",
    "    make_df_column_1_users(data_source_json, 'name', df_name, 'users_name')\n",
    "    make_df_column_1_users(data_source_json, 'username', df_name, 'users_username')\n",
    "    make_df_column_1_users(data_source_json, 'verified', df_name, 'users_verified')\n",
    "    make_df_column_1_users(data_source_json, 'protected', df_name, 'users_protected')\n",
    "    make_df_column_1_users(data_source_json, 'url', df_name, 'users_url')\n",
    "\n",
    "    #use second function for second-order JSON keys (make_df_column_2)\n",
    "    make_df_column_2_users(data_source_json, 'stats', 'followers_count', df_name, 'users_followers_count')\n",
    "    make_df_column_2_users(data_source_json, 'stats', 'following_count', df_name, 'users_following_count')\n",
    "    make_df_column_2_users(data_source_json, 'stats', 'tweet_count', df_name, 'users_tweet_count')\n",
    "    make_df_column_2_users(data_source_json, 'stats', 'listed_count', df_name, 'users_listed_count')\n",
    "    \n",
    "    #use third function for fourth-order JSON keys (make_df_column_3)\n",
    "    make_df_column_4_users(data_source_json, 'entities', 'url', 'urls', 'start', df_name, 'users_url_start')\n",
    "    make_df_column_4_users(data_source_json, 'entities', 'url', 'urls', 'end', df_name, 'users_url_end')\n",
    "    make_df_column_4_users(data_source_json, 'entities', 'url', 'urls', 'expanded_url', df_name, 'users_expanded_url')\n",
    "    make_df_column_4_users(data_source_json, 'entities', 'url', 'urls', 'display_url', df_name, 'users_display_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_investing_df = pd.DataFrame()\n",
    "users_mobile_payment_df = pd.DataFrame()\n",
    "users_mobile_wallet_df = pd.DataFrame()\n",
    "users_mobile_banking_df = pd.DataFrame()\n",
    "users_trading_df = pd.DataFrame()\n",
    "users_fintech_df = pd.DataFrame()\n",
    "users_financial_df = pd.DataFrame()\n",
    "users_money_management_df = pd.DataFrame()\n",
    "users_stocks_df = pd.DataFrame()\n",
    "users_transaction_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_dataframes_users(users_investing_df, users_investing)\n",
    "make_dataframes_users(users_mobile_payment_df, users_mobile_payment)\n",
    "make_dataframes_users(users_mobile_wallet_df, users_mobile_wallet)\n",
    "make_dataframes_users(users_mobile_banking_df, users_mobile_banking)\n",
    "make_dataframes_users(users_trading_df, users_trading)\n",
    "make_dataframes_users(users_fintech_df, users_fintech)\n",
    "make_dataframes_users(users_financial_df, users_financial)\n",
    "make_dataframes_users(users_money_management_df, users_money_management)\n",
    "make_dataframes_users(users_stocks_df, users_stocks)\n",
    "make_dataframes_users(users_transaction_df, users_transaction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge DataFrames Into One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Merge users with tweets.\n",
    "- Merge deets with users + tweets\n",
    "- Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert ID Strings To Integers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Convert strings to int**\n",
    "- deets_tweet_id and users_id columns are strings...need to convert to int before merging with \"tweets\" DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deets_tweet_id is a string...convert to int before merge\n",
    "\n",
    "deets_investing_df['deets_tweet_id'] = deets_investing_df['deets_tweet_id'].astype(int)\n",
    "deets_mobile_payment_df['deets_tweet_id'] = deets_mobile_payment_df['deets_tweet_id'].astype(int)\n",
    "deets_mobile_wallet_df['deets_tweet_id'] = deets_mobile_wallet_df['deets_tweet_id'].astype(int)\n",
    "deets_mobile_banking_df['deets_tweet_id'] = deets_mobile_banking_df['deets_tweet_id'].astype(int)\n",
    "deets_trading_df['deets_tweet_id'] = deets_trading_df['deets_tweet_id'].astype(int)\n",
    "deets_fintech_df['deets_tweet_id'] = deets_fintech_df['deets_tweet_id'].astype(int)\n",
    "deets_financial_df['deets_tweet_id'] = deets_financial_df['deets_tweet_id'].astype(int)\n",
    "deets_money_management_df['deets_tweet_id'] = deets_money_management_df['deets_tweet_id'].astype(int)\n",
    "deets_stocks_df['deets_tweet_id'] = deets_stocks_df['deets_tweet_id'].astype(int)\n",
    "deets_transaction_df['deets_tweet_id'] = deets_transaction_df['deets_tweet_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#users_id is a string...convert to int before merge\n",
    "\n",
    "users_investing_df['users_id'] = users_investing_df['users_id'].astype(int)\n",
    "users_mobile_payment_df['users_id'] = users_mobile_payment_df['users_id'].astype(int)\n",
    "users_mobile_wallet_df['users_id'] = users_mobile_wallet_df['users_id'].astype(int)\n",
    "users_mobile_banking_df['users_id'] = users_mobile_banking_df['users_id'].astype(int)\n",
    "users_trading_df['users_id'] = users_trading_df['users_id'].astype(int)\n",
    "users_fintech_df['users_id'] = users_fintech_df['users_id'].astype(int)\n",
    "users_financial_df['users_id'] = users_financial_df['users_id'].astype(int)\n",
    "users_money_management_df['users_id'] = users_money_management_df['users_id'].astype(int)\n",
    "users_stocks_df['users_id'] = users_stocks_df['users_id'].astype(int)\n",
    "users_transaction_df['users_id'] = users_transaction_df['users_id'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge \"Tweets\" DataFrames With \"Deets\" DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Merge \"tweets\" with \"deets\" using a left join**\n",
    "- If there is no \"deets\" information, then \"NaN\" will show in all \"deets\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "investing_df = pd.merge(\n",
    "    tweets_investing_df, \n",
    "    deets_investing_df, \n",
    "    left_on='tweets_id', \n",
    "    right_on='deets_tweet_id', \n",
    "    how='left')\n",
    "\n",
    "mobile_payment_df = pd.merge(\n",
    "    tweets_mobile_payment_df, \n",
    "    deets_mobile_payment_df, \n",
    "    left_on='tweets_id', \n",
    "    right_on='deets_tweet_id', \n",
    "    how='left')\n",
    "\n",
    "mobile_wallet_df = pd.merge(\n",
    "    tweets_mobile_wallet_df, \n",
    "    deets_mobile_wallet_df, \n",
    "    left_on='tweets_id', \n",
    "    right_on='deets_tweet_id', \n",
    "    how='left')\n",
    "\n",
    "mobile_banking_df = pd.merge(\n",
    "    tweets_mobile_banking_df, \n",
    "    deets_mobile_banking_df, \n",
    "    left_on='tweets_id', \n",
    "    right_on='deets_tweet_id', \n",
    "    how='left')\n",
    "\n",
    "trading_df = pd.merge(\n",
    "    tweets_trading_df, \n",
    "    deets_trading_df, \n",
    "    left_on='tweets_id', \n",
    "    right_on='deets_tweet_id', \n",
    "    how='left')\n",
    "\n",
    "fintech_df = pd.merge(\n",
    "    tweets_fintech_df, \n",
    "    deets_fintech_df, \n",
    "    left_on='tweets_id', \n",
    "    right_on='deets_tweet_id', \n",
    "    how='left')\n",
    "\n",
    "financial_df = pd.merge(\n",
    "    tweets_financial_df, \n",
    "    deets_financial_df, \n",
    "    left_on='tweets_id', \n",
    "    right_on='deets_tweet_id', \n",
    "    how='left')\n",
    "\n",
    "money_management_df = pd.merge(\n",
    "    tweets_money_management_df, \n",
    "    deets_money_management_df, \n",
    "    left_on='tweets_id', \n",
    "    right_on='deets_tweet_id', \n",
    "    how='left')\n",
    "\n",
    "stocks_df = pd.merge(\n",
    "    tweets_stocks_df, \n",
    "    deets_stocks_df, \n",
    "    left_on='tweets_id', \n",
    "    right_on='deets_tweet_id', \n",
    "    how='left')\n",
    "\n",
    "transaction_df = pd.merge(\n",
    "    tweets_transaction_df, \n",
    "    deets_transaction_df, \n",
    "    left_on='tweets_id', \n",
    "    right_on='deets_tweet_id', \n",
    "    how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 47)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure length of rows is still correct...should be 5000:\n",
    "investing_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge \"Tweets + Deets\" DataFrames With \"Users\" DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Merge \"tweets + deets\" DataFrames with \"users\" using a left join**\n",
    "- Need to use pd.drop_duplicates() on each \"users\" DataFrame to ensure that there are no duplicate users that we are merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates in each \"users\" DataFrame and re-assign to a new variable:\n",
    "\n",
    "users_investing_df_unique = users_investing_df.drop_duplicates(subset=['users_id'])\n",
    "users_mobile_payment_df_unique = users_mobile_payment_df.drop_duplicates(subset=['users_id'])\n",
    "users_mobile_wallet_df_unique = users_mobile_wallet_df.drop_duplicates(subset=['users_id'])\n",
    "users_mobile_banking_df_unique = users_mobile_banking_df.drop_duplicates(subset=['users_id'])\n",
    "users_trading_df_unique = users_trading_df.drop_duplicates(subset=['users_id'])\n",
    "users_fintech_df_unique = users_fintech_df.drop_duplicates(subset=['users_id'])\n",
    "users_financial_df_unique = users_financial_df.drop_duplicates(subset=['users_id'])\n",
    "users_money_management_df_unique = users_money_management_df.drop_duplicates(subset=['users_id'])\n",
    "users_stocks_df_unique = users_stocks_df.drop_duplicates(subset=['users_id'])\n",
    "users_transaction_df_unique = users_transaction_df.drop_duplicates(subset=['users_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "investing = pd.merge(\n",
    "    investing_df, \n",
    "    users_investing_df_unique, \n",
    "    left_on='tweets_user_id', \n",
    "    right_on='users_id', \n",
    "    how='left')\n",
    "\n",
    "mobile_payment = pd.merge(\n",
    "    mobile_payment_df, \n",
    "    users_mobile_payment_df_unique, \n",
    "    left_on='tweets_user_id', \n",
    "    right_on='users_id', \n",
    "    how='left')\n",
    "\n",
    "mobile_wallet = pd.merge(\n",
    "    mobile_wallet_df, \n",
    "    users_mobile_wallet_df_unique, \n",
    "    left_on='tweets_user_id', \n",
    "    right_on='users_id', \n",
    "    how='left')\n",
    "\n",
    "mobile_banking = pd.merge(\n",
    "    mobile_banking_df, \n",
    "    users_mobile_banking_df_unique, \n",
    "    left_on='tweets_user_id', \n",
    "    right_on='users_id', \n",
    "    how='left')\n",
    "\n",
    "trading = pd.merge(\n",
    "    trading_df, \n",
    "    users_trading_df_unique, \n",
    "    left_on='tweets_user_id', \n",
    "    right_on='users_id', \n",
    "    how='left')\n",
    "\n",
    "fintech = pd.merge(\n",
    "    fintech_df, \n",
    "    users_fintech_df_unique, \n",
    "    left_on='tweets_user_id', \n",
    "    right_on='users_id', \n",
    "    how='left')\n",
    "\n",
    "financial = pd.merge(\n",
    "    financial_df, \n",
    "    users_financial_df_unique, \n",
    "    left_on='tweets_user_id', \n",
    "    right_on='users_id', \n",
    "    how='left')\n",
    "\n",
    "money_management = pd.merge(\n",
    "    money_management_df, \n",
    "    users_money_management_df_unique, \n",
    "    left_on='tweets_user_id', \n",
    "    right_on='users_id', \n",
    "    how='left')\n",
    "\n",
    "stocks = pd.merge(\n",
    "    stocks_df, \n",
    "    users_stocks_df_unique, \n",
    "    left_on='tweets_user_id', \n",
    "    right_on='users_id', \n",
    "    how='left')\n",
    "\n",
    "transaction = pd.merge(\n",
    "    transaction_df, \n",
    "    users_transaction_df_unique, \n",
    "    left_on='tweets_user_id', \n",
    "    right_on='users_id', \n",
    "    how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Check shape to make sure that all tweets are accounted for**\n",
    "- All \"tweets\" DataFrames should match the number of rows as the \"merged\" DataFrames\n",
    "- There should always be 63 columns in each DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 37)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1226, 37)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2035, 37)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1279, 37)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 37)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4965, 37)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 37)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4998, 37)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4876, 37)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4997, 37)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display shape of original \"tweets\" DataFrames to check merged DataFrames against:\n",
    "\n",
    "display(\n",
    "    tweets_investing_df.shape,\n",
    "    tweets_mobile_payment_df.shape,\n",
    "    tweets_mobile_wallet_df.shape,\n",
    "    tweets_mobile_banking_df.shape,\n",
    "    tweets_trading_df.shape,\n",
    "    tweets_fintech_df.shape,\n",
    "    tweets_financial_df.shape,\n",
    "    tweets_money_management_df.shape,\n",
    "    tweets_stocks_df.shape,\n",
    "    tweets_transaction_df.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 63)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1226, 63)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2035, 63)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1279, 63)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 63)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4965, 63)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5000, 63)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4998, 63)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4876, 63)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4997, 63)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display shape of merged DataFrames \n",
    "# All \"tweets\" DataFrames should match the number of rows as the \"merged\" DataFrames\n",
    "# There should always be 63 columns in each DataFrame\n",
    "\n",
    "display(\n",
    "    investing.shape,\n",
    "    mobile_payment.shape,\n",
    "    mobile_wallet.shape,\n",
    "    mobile_banking.shape,\n",
    "    trading.shape,\n",
    "    fintech.shape,\n",
    "    financial.shape,\n",
    "    money_management.shape,\n",
    "    stocks.shape,\n",
    "    transaction.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yay! Merged DataFrames look good!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat All \"Merged\" DataFrames Together Into One Big DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Concat all \"merged\" DataFrames together into one big DataFrame for further cleaning, analysis, and export\n",
    "- Need to use pd.concat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    investing,\n",
    "    mobile_payment,\n",
    "    mobile_wallet,\n",
    "    mobile_banking,\n",
    "    trading,\n",
    "    fintech,\n",
    "    financial,\n",
    "    money_management,\n",
    "    stocks,\n",
    "    transaction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39376, 63)"
      ]
     },
     "execution_count": 759,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39376"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check length against total length of all DataFrames summed:\n",
    "investing.shape[0] + mobile_payment.shape[0] + mobile_wallet.shape[0] + mobile_banking.shape[0] + trading.shape[0] + fintech.shape[0] + financial.shape[0] + money_management.shape[0] + stocks.shape[0] + transaction.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Yay! Final merged DataFrame matches length!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Raw DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('Twitter_Data_Raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New Features To Add:**\n",
    "- **TWEETS**\n",
    "    - tweets_user_profile_background_color_F5F8FA - top 3 user profile background colors as new columns.\n",
    "    - tweets_user_profile_background_color_C0DEED - top 3 user profile background colors as new columns.\n",
    "    - tweets_user_profile_background_color_000000 - top 3 user profile background colors as new columns.\n",
    "    - tweets_user_profile_text_color_333333 - top 3 user profile text colors as new columns.\n",
    "    - tweets_user_profile_text_color_000000 - top 3 user profile text colors as new columns.\n",
    "    - tweets_user_profile_text_color_666666 - top 3 user profile text colors as new columns.\n",
    "    \n",
    "    \n",
    "- **DEETS**\n",
    "    - deets_text_character_length - create column of number of characters in tweet.\n",
    "\n",
    "    \n",
    "- **USERS**\n",
    "    - users_description_character_length - create column of number of characters in user description.\n",
    "    \n",
    "    \n",
    "- **TARGET**\n",
    "    - retweet_class - Class 0, Class 1, & Class 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['deets_text_character_length'] = df['deets_text'].str.len()\n",
    "df['users_description_character_length'] = df['users_description'].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-Hot-Encoding for user profile color data**\n",
    "- We will be adding the following as one-hot-encoded columns:\n",
    "    - The top 3 most popular user profile background colors.\n",
    "    - The top 3 most popular user profile text colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F5F8FA    13920\n",
       "C0DEED    10363\n",
       "000000     7523\n",
       "Name: tweets_user_profile_background_color, dtype: int64"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one-hot-encode the top 3 background colors as 3 new columns:\n",
    "df['tweets_user_profile_background_color'].value_counts()[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333333    28155\n",
       "000000     7697\n",
       "666666      534\n",
       "Name: tweets_user_profile_text_color, dtype: int64"
      ]
     },
     "execution_count": 764,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one-hot-encode the top 3 text colors as 3 new columns:\n",
    "df['tweets_user_profile_text_color'].value_counts()[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot-encode for \"tweets_user_profile_background_color\"\n",
    "enc_1 = OneHotEncoder()\n",
    "enc_1_df = pd.DataFrame(enc_1.fit_transform(df[['tweets_user_profile_background_color']]).toarray())\n",
    "enc_1_df.columns = enc_1.get_feature_names()\n",
    "enc_1_df.columns = enc_1_df.columns.str[3:]\n",
    "\n",
    "#assign the top 3 user profile background colors as new columns in df\n",
    "df['tweets_user_profile_background_color_F5F8FA'] = enc_1_df['F5F8FA']\n",
    "df['tweets_user_profile_background_color_C0DEED'] = enc_1_df['C0DEED']\n",
    "df['tweets_user_profile_background_color_000000'] = enc_1_df['000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one-hot-encode for \"tweets_user_profile_text_color\"\n",
    "enc_2 = OneHotEncoder()\n",
    "enc_2_df = pd.DataFrame(enc_2.fit_transform(df[['tweets_user_profile_text_color']]).toarray())\n",
    "enc_2_df.columns = enc_2.get_feature_names()\n",
    "enc_2_df.columns = enc_2_df.columns.str[3:]\n",
    "\n",
    "#assign the top 3 user profile text colors as new columns in df\n",
    "df['tweets_user_profile_text_color_333333'] = enc_2_df['333333']\n",
    "df['tweets_user_profile_text_color_000000'] = enc_2_df['000000']\n",
    "df['tweets_user_profile_text_color_666666'] = enc_2_df['666666']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Target Classification Column \"retweet_class\"**\n",
    "- We will be creating 3 classes of retweet_counts:\n",
    "    - Class 0 = 0-100 retweets\n",
    "    - Class 1 = 100-1000 retweets\n",
    "    - Class 2 = 1000+ retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['tweets_retweet_count'] <= 100, 'retweet_class'] = 0\n",
    "df.loc[(df['tweets_retweet_count'] > 100) & (df['tweets_retweet_count'] <= 1000), 'retweet_class'] = 1\n",
    "df.loc[df['tweets_retweet_count'] > 1000, 'retweet_class'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Columns To Drop:**\n",
    "- **TWEETS**\n",
    "    - tweets_coordinates - not enough data (86 rows)\n",
    "    - tweets_geo - not enough data (86 rows)\n",
    "    - tweets_place - not enough data (445 rows)\n",
    "    - tweets_contributors - not enough data (0 rows)\n",
    "    - tweets_user_following - not enough data (0 rows)\n",
    "    - tweets_user_follow_request_sent - not enough data (0 rows)\n",
    "    - tweets_user_notifications - not enough data (0 rows)\n",
    "    - tweets_in_reply_to_status_id - not useful data.\n",
    "    - tweets_in_reply_to_user_id - not useful data.\n",
    "    - tweets_in_reply_to_screen_name - not useful data.\n",
    "    - tweets_source - not data that we really care about.\n",
    "    - tweets_entities_symbols - out of time to work more with this feature.\n",
    "    - tweets_entities_user_mentions - out of time to work more with this feature.\n",
    "    - tweets_entities_urls - out of time to work more with this feature.\n",
    "    \n",
    "    \n",
    "- **DEETS**\n",
    "    - deets_author_id - this is the same as users_id...no need to have a duplicate column.\n",
    "    - deets_tweet_id - this is the same as tweets_id...no need to have a duplicate column.\n",
    "    - deets_source - not data that we really care about\n",
    "    - deets_lang - we already filtered by \"english\" when we called tweets. No need for this column.\n",
    "    - deets_created_at - we already have tweets_created_at - this is the same thing. No need for this column.\n",
    "\n",
    "\n",
    "- **USERS**\n",
    "    - users_url_start - after analyzing, we aren't sure what this data really means, so we don't want to use it.\n",
    "    - users_url_end - after analyzing, we aren't sure what this data really means, so we don't want to use it.\n",
    "    \n",
    "        'tweets_id',\n",
    "    'tweets_user_name',\n",
    "    'tweet_user_screen_name',\n",
    "    'tweets_user_profile_background_color',\n",
    "    'tweets_user_profile_text_color',\n",
    "    'users_name',\n",
    "    'users_username',\n",
    "    'users_url',\n",
    "    'users_expanded_url',\n",
    "    'users_display_url',\n",
    "    'tweets_retweet_count',\n",
    "    'tweets_created_at',\n",
    "    'tweets_user_location',\n",
    "    'users_created_at',\n",
    "    'tweets_user_description',\n",
    "    'deets_text',\n",
    "    'users_description',\n",
    "    'tweets_user_id',\n",
    "    'users_id',\n",
    "    'tweets_user_verified',\n",
    "    'tweets_retweeted,\n",
    "    'tweets_favorited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\n",
    "    'tweets_coordinates',\n",
    "    'tweets_geo',\n",
    "    'tweets_place',\n",
    "    'tweets_contributors',\n",
    "    'tweets_user_following',\n",
    "    'tweets_user_follow_request_sent',\n",
    "    'tweets_user_notifications',\n",
    "    'tweets_in_reply_to_status_id',\n",
    "    'tweets_in_reply_to_user_id',\n",
    "    'tweets_in_reply_to_screen_name',\n",
    "    'tweets_source',\n",
    "    'tweets_entities_symbols',\n",
    "    'tweets_entities_user_mentions',\n",
    "    'tweets_entities_urls',\n",
    "    'deets_tweet_id',\n",
    "    'deets_source',\n",
    "    'deets_author_id',\n",
    "    'deets_lang',\n",
    "    'deets_created_at',\n",
    "    'users_url_start',\n",
    "    'users_url_end',\n",
    "    'tweets_id',\n",
    "    'tweets_user_name',\n",
    "    'tweet_user_screen_name',\n",
    "    'tweets_user_profile_background_color',\n",
    "    'tweets_user_profile_text_color',\n",
    "    'users_name',\n",
    "    'users_username',\n",
    "    'users_url',\n",
    "    'users_expanded_url',\n",
    "    'users_display_url',\n",
    "    'tweets_retweet_count',\n",
    "    'tweets_created_at',\n",
    "    'tweets_user_location',\n",
    "    'users_created_at',\n",
    "    'tweets_user_description',\n",
    "    'deets_text',\n",
    "    'users_description',\n",
    "    'tweets_user_id',\n",
    "    'users_id',\n",
    "    'tweets_user_verified',\n",
    "    'tweets_retweeted',\n",
    "    'tweets_favorited'], \n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Column Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Columns To Convert:**\n",
    "- **TWEETS**\n",
    "    - NONE\n",
    "\n",
    "\n",
    "- **DEETS**\n",
    "    - deets_possibly_sensitive - str to bool\n",
    "\n",
    "\n",
    "- **USERS**\n",
    "    - NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deets\n",
    "df['deets_possibly_sensitive'] = df['deets_possibly_sensitive'].astype(bool)\n",
    "df['users_verified'] = df['users_verified'].astype(bool)\n",
    "df['users_protected'] = df['users_protected'].astype(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter DataFrame Rows By \"Startup\" Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our business case is for a financial tech startup company.\n",
    "- This startup company is likely to only have a few thousand followers at best.\n",
    "- Tweets by Twitter influencers with millions of followers will be weighted too heavily in predicting more retweets...\n",
    "- Based on our research, we have found that startup companies tend to have a follower count between 1,000 and 10,000.\n",
    "- **So, to control for this, we are only interested in tweets by users that have a follower count between 1,000 and 10,000, like our startup company.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter tweets by users with follower count between 1,000 and 10,000\n",
    "df = df.loc[(df['users_followers_count'] >= 1000) & (df['users_followers_count'] <= 10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12070, 29)"
      ]
     },
     "execution_count": 772,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many rows of data did we lose?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After filtering, we lost about 2/3 of our data. (39376 rows --> 12070 rows)\n",
    "- But we still have over 10,000 rows to work with, this should still be adequate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing Values As Necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out where NaN values are in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweets_is_quote_status                           0\n",
       "tweets_favorite_count                            0\n",
       "tweets_user_friends_count                        0\n",
       "tweets_user_followers_count                      0\n",
       "tweets_user_favourites_count                     0\n",
       "tweets_user_geo_enabled                          0\n",
       "tweets_user_statuses_count                       0\n",
       "tweets_user_profile_use_background_image         0\n",
       "tweets_user_has_extended_profile                 0\n",
       "tweets_user_default_profile_image                0\n",
       "deets_possibly_sensitive                         0\n",
       "deets_reply_count                              331\n",
       "deets_like_count                               331\n",
       "deets_quote_count                              331\n",
       "users_verified                                   0\n",
       "users_protected                                  0\n",
       "users_followers_count                            0\n",
       "users_following_count                            0\n",
       "users_tweet_count                                0\n",
       "users_listed_count                               0\n",
       "deets_text_character_length                    331\n",
       "users_description_character_length               0\n",
       "tweets_user_profile_background_color_F5F8FA      0\n",
       "tweets_user_profile_background_color_C0DEED      0\n",
       "tweets_user_profile_background_color_000000      0\n",
       "tweets_user_profile_text_color_333333            0\n",
       "tweets_user_profile_text_color_000000            0\n",
       "tweets_user_profile_text_color_666666            0\n",
       "retweet_class                                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are 331 NaN values in:**\n",
    "- deets_reply_count\n",
    "- deets_like_count\n",
    "- deets_quote_count\n",
    "- deets_text_word_length\n",
    "- deets_text_character_length\n",
    "\n",
    "\n",
    "**Losing 331 rows isn't too much of a loss. We will eliminate these ^ rows of NaN data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows where there are NaN values in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='any', axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweets_is_quote_status                         0\n",
       "tweets_favorite_count                          0\n",
       "tweets_user_friends_count                      0\n",
       "tweets_user_followers_count                    0\n",
       "tweets_user_favourites_count                   0\n",
       "tweets_user_geo_enabled                        0\n",
       "tweets_user_statuses_count                     0\n",
       "tweets_user_profile_use_background_image       0\n",
       "tweets_user_has_extended_profile               0\n",
       "tweets_user_default_profile_image              0\n",
       "deets_possibly_sensitive                       0\n",
       "deets_reply_count                              0\n",
       "deets_like_count                               0\n",
       "deets_quote_count                              0\n",
       "users_verified                                 0\n",
       "users_protected                                0\n",
       "users_followers_count                          0\n",
       "users_following_count                          0\n",
       "users_tweet_count                              0\n",
       "users_listed_count                             0\n",
       "deets_text_character_length                    0\n",
       "users_description_character_length             0\n",
       "tweets_user_profile_background_color_F5F8FA    0\n",
       "tweets_user_profile_background_color_C0DEED    0\n",
       "tweets_user_profile_background_color_000000    0\n",
       "tweets_user_profile_text_color_333333          0\n",
       "tweets_user_profile_text_color_000000          0\n",
       "tweets_user_profile_text_color_666666          0\n",
       "retweet_class                                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11739, 29)"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 11739 entries, 5 to 39372\n",
      "Data columns (total 29 columns):\n",
      "tweets_is_quote_status                         11739 non-null bool\n",
      "tweets_favorite_count                          11739 non-null int64\n",
      "tweets_user_friends_count                      11739 non-null int64\n",
      "tweets_user_followers_count                    11739 non-null int64\n",
      "tweets_user_favourites_count                   11739 non-null int64\n",
      "tweets_user_geo_enabled                        11739 non-null bool\n",
      "tweets_user_statuses_count                     11739 non-null int64\n",
      "tweets_user_profile_use_background_image       11739 non-null bool\n",
      "tweets_user_has_extended_profile               11739 non-null bool\n",
      "tweets_user_default_profile_image              11739 non-null bool\n",
      "deets_possibly_sensitive                       11739 non-null bool\n",
      "deets_reply_count                              11739 non-null float64\n",
      "deets_like_count                               11739 non-null float64\n",
      "deets_quote_count                              11739 non-null float64\n",
      "users_verified                                 11739 non-null bool\n",
      "users_protected                                11739 non-null bool\n",
      "users_followers_count                          11739 non-null float64\n",
      "users_following_count                          11739 non-null float64\n",
      "users_tweet_count                              11739 non-null float64\n",
      "users_listed_count                             11739 non-null float64\n",
      "deets_text_character_length                    11739 non-null float64\n",
      "users_description_character_length             11739 non-null float64\n",
      "tweets_user_profile_background_color_F5F8FA    11739 non-null float64\n",
      "tweets_user_profile_background_color_C0DEED    11739 non-null float64\n",
      "tweets_user_profile_background_color_000000    11739 non-null float64\n",
      "tweets_user_profile_text_color_333333          11739 non-null float64\n",
      "tweets_user_profile_text_color_000000          11739 non-null float64\n",
      "tweets_user_profile_text_color_666666          11739 non-null float64\n",
      "retweet_class                                  11739 non-null float64\n",
      "dtypes: bool(8), float64(16), int64(5)\n",
      "memory usage: 2.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DataFrame is now ready to be fed into modeling processes.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Twitter_Data_Final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "259.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
